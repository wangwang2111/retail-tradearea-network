{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b896cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "src = \"data/raw/census/98-401-X2021006_English_CSV_data_Ontario.csv\"\n",
    "out_wide = \"data/processed/census_profile_on_DA_wide.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be1f734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CENSUS_YEAR', 'DGUID', 'ALT_GEO_CODE', 'GEO_LEVEL', 'GEO_NAME',\n",
      "       'TNR_SF', 'TNR_LF', 'DATA_QUALITY_FLAG', 'CHARACTERISTIC_ID',\n",
      "       'CHARACTERISTIC_NAME', 'CHARACTERISTIC_NOTE', 'C1_COUNT_TOTAL',\n",
      "       'SYMBOL', 'C2_COUNT_MEN+', 'SYMBOL.1', 'C3_COUNT_WOMEN+', 'SYMBOL.2',\n",
      "       'C10_RATE_TOTAL', 'SYMBOL.3', 'C11_RATE_MEN+', 'SYMBOL.4',\n",
      "       'C12_RATE_WOMEN+', 'SYMBOL.5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_head = pd.read_csv(src, nrows=5, encoding='latin1')\n",
    "print(df_head.columns)   # show first 40 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62cae93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CENSUS_YEAR</th>\n",
       "      <th>DGUID</th>\n",
       "      <th>ALT_GEO_CODE</th>\n",
       "      <th>GEO_LEVEL</th>\n",
       "      <th>GEO_NAME</th>\n",
       "      <th>TNR_SF</th>\n",
       "      <th>TNR_LF</th>\n",
       "      <th>DATA_QUALITY_FLAG</th>\n",
       "      <th>CHARACTERISTIC_ID</th>\n",
       "      <th>CHARACTERISTIC_NAME</th>\n",
       "      <th>CHARACTERISTIC_NOTE</th>\n",
       "      <th>C1_COUNT_TOTAL</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>C2_COUNT_MEN+</th>\n",
       "      <th>SYMBOL.1</th>\n",
       "      <th>C3_COUNT_WOMEN+</th>\n",
       "      <th>SYMBOL.2</th>\n",
       "      <th>C10_RATE_TOTAL</th>\n",
       "      <th>SYMBOL.3</th>\n",
       "      <th>C11_RATE_MEN+</th>\n",
       "      <th>SYMBOL.4</th>\n",
       "      <th>C12_RATE_WOMEN+</th>\n",
       "      <th>SYMBOL.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021A000011124</td>\n",
       "      <td>1</td>\n",
       "      <td>Country</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>Population, 2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36991981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021A000011124</td>\n",
       "      <td>1</td>\n",
       "      <td>Country</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>Population, 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35151728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CENSUS_YEAR           DGUID  ALT_GEO_CODE GEO_LEVEL GEO_NAME  TNR_SF  \\\n",
       "0         2021  2021A000011124             1   Country   Canada     3.1   \n",
       "1         2021  2021A000011124             1   Country   Canada     3.1   \n",
       "\n",
       "   TNR_LF  DATA_QUALITY_FLAG  CHARACTERISTIC_ID CHARACTERISTIC_NAME  \\\n",
       "0     4.3              20000                  1    Population, 2021   \n",
       "1     4.3              20000                  2    Population, 2016   \n",
       "\n",
       "   CHARACTERISTIC_NOTE  C1_COUNT_TOTAL  SYMBOL  C2_COUNT_MEN+ SYMBOL.1  \\\n",
       "0                  1.0      36991981.0     NaN            NaN      ...   \n",
       "1                  1.0      35151728.0     NaN            NaN      ...   \n",
       "\n",
       "   C3_COUNT_WOMEN+ SYMBOL.2  C10_RATE_TOTAL SYMBOL.3  C11_RATE_MEN+ SYMBOL.4  \\\n",
       "0              NaN      ...             NaN      ...            NaN      ...   \n",
       "1              NaN      ...             NaN      ...            NaN      ...   \n",
       "\n",
       "   C12_RATE_WOMEN+ SYMBOL.5  \n",
       "0              NaN      ...  \n",
       "1              NaN      ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# You can also set the maximum column width to prevent truncation of long values\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_head.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct GEO_LEVELs: ['Census division', 'Census subdivision', 'Country', 'Dissemination area', 'Province']\n",
      "\n",
      "--- candidates for: Population ---\n",
      "                                                                                                              Population, 2021\n",
      "                                                                                                              Population, 2016\n",
      "                                                                                    Population percentage change, 2016 to 2021\n",
      "                                                                                       Population density per square kilometre\n",
      "                                                                              Total - Age groups of the population - 100% data\n",
      "                                                    Total - Distribution (%) of the population by broad age groups - 100% data\n",
      "                                                                                                 Average age of the population\n",
      "                                                                                                  Median age of the population\n",
      "                                            Total - Marital status for the total population aged 15 years and over - 100% data\n",
      "                 Total - Income statistics in 2020 for the population aged 15 years and over in private households - 100% data\n",
      "           Total - Income statistics in 2020 for the population aged 15 years and over in private households - 25% sample data\n",
      "Total - Employment income statistics in 2020 for the population aged 15 years and over in private households - 25% sample data\n",
      "      Composition of total income in 2020 of the population aged 15 years and over in private households (%) - 25% sample data\n",
      "               Total - Total income groups in 2020 for the population aged 15 years and over in private households - 100% data\n",
      "           Total - After-tax income groups in 2020 for the population aged 15 years and over in private households - 100% data\n",
      "          Total - Employment income groups in 2020 for the population aged 15 years and over in private households - 100% data\n",
      "                 Total - Income statistics in 2019 for the population aged 15 years and over in private households - 100% data\n",
      "           Total - Income statistics in 2019 for the population aged 15 years and over in private households - 25% sample data\n",
      "Total - Employment income statistics in 2019 for the population aged 15 years and over in private households - 25% sample data\n",
      "      Composition of total income in 2019 of the population aged 15 years and over in private households (%) - 25% sample data\n",
      "\n",
      "--- candidates for: household ---\n",
      "                                                     Total - Private households by household size - 100% data\n",
      "                                                                      Number of persons in private households\n",
      "                                                                                       Average household size\n",
      "                                     Total - Census families in private households by family size - 100% data\n",
      "                                            Total number of census families in private households - 100% data\n",
      "                                                            Total - Persons in private households - 100% data\n",
      "                                     Total - Persons not in census families in private households - 100% data\n",
      "                                                                           Total - Household type - 100% data\n",
      "                                                      One-census-family households without additional persons\n",
      "                                                                                     Couple-family households\n",
      "                                                                                 One-parent-family households\n",
      "                                                                                 Multigenerational households\n",
      "                                                                            Multiple-census-family households\n",
      "                                                         One-census-family households with additional persons\n",
      "                                                             Two-or-more-person non-census-family households \n",
      "                                                                                        One-person households\n",
      "Total - Income statistics in 2020 for the population aged 15 years and over in private households - 100% data\n",
      "           Number of total income recipients aged 15 years and over in private households in 2020 - 100% data\n",
      "       Number of after-tax income recipients aged 15 years and over in private households in 2020 - 100% data\n",
      "          Number of market income recipients aged 15 years and over in private households in 2020 - 100% data\n",
      "\n",
      "--- candidates for: Median total income of households ---\n",
      "Series([], )\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "src = \"data/raw/census/98-401-X2021006_English_CSV_data_Ontario.csv\"\n",
    "\n",
    "peek = pd.read_csv(src, nrows=50_000, encoding=\"latin1\",\n",
    "                   usecols=[\"GEO_LEVEL\",\"ALT_GEO_CODE\",\"CHARACTERISTIC_ID\",\n",
    "                            \"CHARACTERISTIC_NAME\",\"C1_COUNT_TOTAL\",\"C10_RATE_TOTAL\"])\n",
    "print(\"distinct GEO_LEVELs:\", sorted(peek[\"GEO_LEVEL\"].dropna().unique().tolist())[:10])\n",
    "\n",
    "# See what 'Population' / 'household' / 'median' strings look like in file\n",
    "for kw in [\"Population\", \"household\", \"Median total income of households\"]:\n",
    "    print(f\"\\n--- candidates for: {kw} ---\")\n",
    "    print(peek.loc[peek[\"CHARACTERISTIC_NAME\"].str.contains(kw, case=False, na=False),\n",
    "                   \"CHARACTERISTIC_NAME\"].drop_duplicates().head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728fc8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chunk 1 appended: 548 rows\n",
      "✅ chunk 2 appended: 535 rows\n",
      "✅ chunk 3 appended: 564 rows\n",
      "✅ chunk 4 appended: 570 rows\n",
      "✅ chunk 5 appended: 570 rows\n",
      "✅ chunk 6 appended: 570 rows\n",
      "✅ chunk 7 appended: 570 rows\n",
      "✅ chunk 8 appended: 570 rows\n",
      "✅ chunk 9 appended: 570 rows\n",
      "✅ chunk 10 appended: 552 rows\n",
      "✅ chunk 11 appended: 522 rows\n",
      "✅ chunk 12 appended: 555 rows\n",
      "✅ chunk 13 appended: 534 rows\n",
      "✅ chunk 14 appended: 555 rows\n",
      "✅ chunk 15 appended: 519 rows\n",
      "✅ chunk 16 appended: 543 rows\n",
      "✅ chunk 17 appended: 546 rows\n",
      "✅ chunk 18 appended: 561 rows\n",
      "✅ chunk 19 appended: 567 rows\n",
      "✅ chunk 20 appended: 567 rows\n",
      "✅ chunk 21 appended: 570 rows\n",
      "✅ chunk 22 appended: 567 rows\n",
      "✅ chunk 23 appended: 552 rows\n",
      "✅ chunk 24 appended: 571 rows\n",
      "✅ chunk 25 appended: 568 rows\n",
      "✅ chunk 26 appended: 567 rows\n",
      "✅ chunk 27 appended: 568 rows\n",
      "✅ chunk 28 appended: 564 rows\n",
      "✅ chunk 29 appended: 552 rows\n",
      "✅ chunk 30 appended: 570 rows\n",
      "✅ chunk 31 appended: 570 rows\n",
      "✅ chunk 32 appended: 570 rows\n",
      "✅ chunk 33 appended: 570 rows\n",
      "✅ chunk 34 appended: 570 rows\n",
      "✅ chunk 35 appended: 570 rows\n",
      "✅ chunk 36 appended: 570 rows\n",
      "✅ chunk 37 appended: 570 rows\n",
      "✅ chunk 38 appended: 570 rows\n",
      "✅ chunk 39 appended: 570 rows\n",
      "✅ chunk 40 appended: 570 rows\n",
      "✅ chunk 41 appended: 570 rows\n",
      "✅ chunk 42 appended: 570 rows\n",
      "✅ chunk 43 appended: 570 rows\n",
      "✅ chunk 44 appended: 570 rows\n",
      "✅ chunk 45 appended: 570 rows\n",
      "✅ chunk 46 appended: 570 rows\n",
      "✅ chunk 47 appended: 570 rows\n",
      "✅ chunk 48 appended: 571 rows\n",
      "✅ chunk 49 appended: 565 rows\n",
      "✅ chunk 50 appended: 570 rows\n",
      "✅ chunk 51 appended: 571 rows\n",
      "✅ chunk 52 appended: 570 rows\n",
      "✅ chunk 53 appended: 570 rows\n",
      "✅ chunk 54 appended: 567 rows\n",
      "✅ chunk 55 appended: 570 rows\n",
      "✅ chunk 56 appended: 570 rows\n",
      "✅ chunk 57 appended: 570 rows\n",
      "✅ chunk 58 appended: 549 rows\n",
      "✅ chunk 59 appended: 552 rows\n",
      "✅ chunk 60 appended: 558 rows\n",
      "✅ chunk 61 appended: 558 rows\n",
      "✅ chunk 62 appended: 567 rows\n",
      "✅ chunk 63 appended: 570 rows\n",
      "✅ chunk 64 appended: 567 rows\n",
      "✅ chunk 65 appended: 561 rows\n",
      "✅ chunk 66 appended: 570 rows\n",
      "✅ chunk 67 appended: 570 rows\n",
      "✅ chunk 68 appended: 570 rows\n",
      "✅ chunk 69 appended: 570 rows\n",
      "✅ chunk 70 appended: 555 rows\n",
      "✅ chunk 71 appended: 558 rows\n",
      "✅ chunk 72 appended: 565 rows\n",
      "✅ chunk 73 appended: 568 rows\n",
      "✅ chunk 74 appended: 553 rows\n",
      "✅ chunk 75 appended: 561 rows\n",
      "✅ chunk 76 appended: 555 rows\n",
      "✅ chunk 77 appended: 567 rows\n",
      "✅ chunk 78 appended: 570 rows\n",
      "✅ chunk 79 appended: 567 rows\n",
      "✅ chunk 80 appended: 555 rows\n",
      "✅ chunk 81 appended: 534 rows\n",
      "✅ chunk 82 appended: 546 rows\n",
      "✅ chunk 83 appended: 555 rows\n",
      "✅ chunk 84 appended: 555 rows\n",
      "✅ chunk 85 appended: 558 rows\n",
      "✅ chunk 86 appended: 570 rows\n",
      "✅ chunk 87 appended: 564 rows\n",
      "✅ chunk 88 appended: 540 rows\n",
      "✅ chunk 89 appended: 537 rows\n",
      "✅ chunk 90 appended: 558 rows\n",
      "✅ chunk 91 appended: 570 rows\n",
      "✅ chunk 92 appended: 570 rows\n",
      "✅ chunk 93 appended: 540 rows\n",
      "✅ chunk 94 appended: 513 rows\n",
      "✅ chunk 95 appended: 543 rows\n",
      "✅ chunk 96 appended: 556 rows\n",
      "✅ chunk 97 appended: 556 rows\n",
      "✅ chunk 98 appended: 571 rows\n",
      "✅ chunk 99 appended: 543 rows\n",
      "✅ chunk 100 appended: 519 rows\n",
      "✅ chunk 101 appended: 495 rows\n",
      "✅ chunk 102 appended: 510 rows\n",
      "✅ chunk 103 appended: 405 rows\n",
      "✅ chunk 104 appended: 561 rows\n",
      "✅ chunk 105 appended: 486 rows\n",
      "✅ chunk 106 appended: 483 rows\n",
      "✅ chunk 107 appended: 528 rows\n",
      "✅ chunk 108 appended: 513 rows\n",
      "✅ chunk 109 appended: 507 rows\n",
      "✅ chunk 110 appended: 441 rows\n",
      "✅ chunk 111 appended: 417 rows\n",
      "✅ chunk 112 appended: 3 rows\n",
      "✅ Saved: data/processed/census_on_DA_wide.csv (20408, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# INPUT / OUTPUT\n",
    "SRC = \"data/raw/census/98-401-X2021006_English_CSV_data_Ontario.csv\"\n",
    "LONG_OUT = \"data/processed/census_on_DA_long.csv\"\n",
    "WIDE_OUT = \"data/processed/census_on_DA_wide.csv\"\n",
    "\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Helpers to normalize strings ---\n",
    "def norm(s: pd.Series) -> pd.Series:\n",
    "    # strip, collapse multiple spaces to one, lowercase\n",
    "    return (s.astype(str)\n",
    "              .str.strip()\n",
    "              .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "              .str.lower())\n",
    "\n",
    "# Target characteristic names (normalized)\n",
    "# Note: you said your file has leading spaces and \"household\" (singular).\n",
    "TARGETS_CANON_TO_OUT = {\n",
    "    \"population, 2021\": \"Population_2021\",\n",
    "    \"total - private households by household size - 100% data\": \"Total_households\",\n",
    "    \"median total income of household in 2020 ($)\": \"Median_income_2020\",\n",
    "}\n",
    "\n",
    "# Columns to read (keeps memory down)\n",
    "USECOLS = [\n",
    "    \"GEO_LEVEL\",\n",
    "    \"ALT_GEO_CODE\",           # DAUID for DA rows\n",
    "    \"CHARACTERISTIC_NAME\",\n",
    "    \"C1_COUNT_TOTAL\",         # counts (population/households)\n",
    "    \"C10_RATE_TOTAL\"          # medians/rates (median income)\n",
    "]\n",
    "\n",
    "# Initialize the long output file with header\n",
    "pd.DataFrame(columns=[\"DAUID\", \"characteristic\", \"value\"]).to_csv(LONG_OUT, index=False)\n",
    "\n",
    "chunksize = 500_000\n",
    "for i, chunk in enumerate(pd.read_csv(\n",
    "        SRC,\n",
    "        encoding=\"latin1\",\n",
    "        usecols=USECOLS,\n",
    "        chunksize=chunksize,\n",
    "        low_memory=False)):\n",
    "\n",
    "    # Normalize GEO_LEVEL and filter DA rows\n",
    "    geo_level = norm(chunk[\"GEO_LEVEL\"])\n",
    "    chunk = chunk[geo_level.eq(\"dissemination area\")]\n",
    "\n",
    "    if chunk.empty:\n",
    "        print(f\"chunk {i+1}: no DA rows, skipped\")\n",
    "        continue\n",
    "\n",
    "    # Normalize characteristic names for matching\n",
    "    char_norm = norm(chunk[\"CHARACTERISTIC_NAME\"])\n",
    "\n",
    "    # Keep only target characteristics (normalized match)\n",
    "    keep_mask = char_norm.isin(TARGETS_CANON_TO_OUT.keys())\n",
    "    chunk = chunk[keep_mask].copy()\n",
    "    if chunk.empty:\n",
    "        print(f\"chunk {i+1}: no target characteristics, skipped\")\n",
    "        continue\n",
    "\n",
    "    # Coalesce value: prefer counts, else rate/median\n",
    "    chunk[\"value\"] = chunk[\"C1_COUNT_TOTAL\"].where(\n",
    "        chunk[\"C1_COUNT_TOTAL\"].notna(),\n",
    "        chunk[\"C10_RATE_TOTAL\"]\n",
    "    )\n",
    "\n",
    "    # Build normalized characteristic label (canonical)\n",
    "    chunk[\"characteristic\"] = char_norm.map(TARGETS_CANON_TO_OUT)\n",
    "\n",
    "    # DAUID as string with leading zeros\n",
    "    chunk[\"DAUID\"] = chunk[\"ALT_GEO_CODE\"].astype(str).str.zfill(8)\n",
    "\n",
    "    # Keep only the essentials\n",
    "    out_long = chunk.loc[:, [\"DAUID\", \"characteristic\", \"value\"]]\n",
    "\n",
    "    # Append to disk (so we never hold everything in RAM)\n",
    "    out_long.to_csv(LONG_OUT, mode=\"a\", header=False, index=False)\n",
    "\n",
    "    print(f\"✅ chunk {i+1} appended: {len(out_long)} rows\")\n",
    "\n",
    "# --- Pivot long → wide (this file is now small enough for RAM) ---\n",
    "long_df = pd.read_csv(LONG_OUT)\n",
    "wide = long_df.pivot_table(\n",
    "    index=\"DAUID\",\n",
    "    columns=\"characteristic\",\n",
    "    values=\"value\",\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "# Ensure numeric dtype\n",
    "for col in [\"Population_2021\", \"Total_households\", \"Median_income_2020\"]:\n",
    "    if col in wide.columns:\n",
    "        wide[col] = pd.to_numeric(wide[col], errors=\"coerce\")\n",
    "\n",
    "# Save final wide table\n",
    "wide.to_csv(WIDE_OUT, index=False)\n",
    "print(\"✅ Saved:\", WIDE_OUT, wide.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcebe1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAs joined: 20408\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DA_SHAPE = \"data/raw/geo/lda_000a21a_e/lda_000a21a_e.shp\"   # 2021 DA Digital Boundary\n",
    "DEMO_CSV = \"data/processed/census_on_DA_wide.csv\"\n",
    "ISO_SHAPE = \"data/raw/geo/branches_isochrones.shp\"\n",
    "\n",
    "OUT_TABLE = \"data/outputs/trade_area_demographics.csv\"\n",
    "OUT_GEO   = \"data/outputs/trade_area_demographics.geojson\"\n",
    "OUT_SHP   = \"data/outputs/trade_area_demographics.shp\"\n",
    "Path(\"data/outputs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load DAs and demo\n",
    "da = gpd.read_file(DA_SHAPE)\n",
    "demo = pd.read_csv(DEMO_CSV, dtype={\"DAUID\":\"string\"})\n",
    "\n",
    "# Normalize keys\n",
    "da[\"DAUID\"]  = da[\"DAUID\"].astype(str).str.zfill(8)\n",
    "demo[\"DAUID\"] = demo[\"DAUID\"].str.zfill(8)\n",
    "\n",
    "# (Robust Ontario filter)\n",
    "#  - Prefer PRNAME if present\n",
    "#  - else use DAUID prefix (Ontario = \"35\")\n",
    "if \"PRNAME\" in da.columns:\n",
    "    da_on = da[da[\"PRNAME\"].eq(\"Ontario\")].copy()\n",
    "else:\n",
    "    da_on = da[da[\"DAUID\"].str.startswith(\"35\")].copy()\n",
    "\n",
    "# Join attributes\n",
    "gda = da_on.merge(demo, on=\"DAUID\", how=\"inner\")\n",
    "print(\"DAs joined:\", len(gda))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52184dc",
   "metadata": {},
   "source": [
    "2) Prep CRS for correct areas (projected meters)\n",
    "\n",
    "Keep computations in EPSG:3347 (NAD83 / StatsCan Lambert) for accurate areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67258cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure projected CRS (3347) for area math\n",
    "if gda.crs is None or gda.crs.to_epsg() not in (3347,):\n",
    "    gda = gda.to_crs(3347)\n",
    "\n",
    "# Original DA areas (used for area-weighting)\n",
    "gda[\"DA_area_m2\"] = gda.geometry.area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3183ce6",
   "metadata": {},
   "source": [
    "3) Read your isochrones and match CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadaf0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = gpd.read_file(ISO_SHAPE)\n",
    "if iso.crs is None or iso.crs.to_epsg() != 3347:\n",
    "    iso = iso.to_crs(3347)\n",
    "\n",
    "# (Optional) dissolve tiny slivers & simplify grouping keys\n",
    "# Keep only what we need for grouping\n",
    "keep_cols = [c for c in iso.columns if c in (\"FacilityID\",\"ToBreak\",\"FromBreak\",\"Name\")]\n",
    "iso = iso[keep_cols + [\"geometry\"]].copy()\n",
    "\n",
    "# Dissolve per FacilityID & ToBreak to reduce overlay complexity (optional but helpful)\n",
    "iso_diss = iso.dissolve(by=[\"FacilityID\",\"ToBreak\"], as_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a33aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_315127/3564444109.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_agg)\n",
      "/tmp/ipykernel_315127/3564444109.py:45: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  inter.to_file(OUT_SHP, driver=\"ESRI Shapefile\")\n",
      "/home/dylannguyen/anaconda3/envs/geopanda/lib/python3.10/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Median_income_2020' to 'Median_inc'\n",
      "  ogr_write(\n",
      "/home/dylannguyen/anaconda3/envs/geopanda/lib/python3.10/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Population_2021' to 'Population'\n",
      "  ogr_write(\n",
      "/home/dylannguyen/anaconda3/envs/geopanda/lib/python3.10/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'Total_households' to 'Total_hous'\n",
      "  ogr_write(\n",
      "/home/dylannguyen/anaconda3/envs/geopanda/lib/python3.10/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'part_area_m2' to 'part_area_'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table: data/outputs/trade_area_demographics.csv\n",
      "✅ Saved GeoJSON and SHP in data/outputs/\n"
     ]
    }
   ],
   "source": [
    "# Spatial overlay\n",
    "inter = gpd.overlay(gda, iso_diss, how=\"intersection\")\n",
    "\n",
    "# Areas & weights\n",
    "inter[\"part_area_m2\"] = inter.geometry.area\n",
    "inter[\"w\"] = (inter[\"part_area_m2\"] / inter[\"DA_area_m2\"]).clip(upper=1).fillna(0)\n",
    "\n",
    "# Ensure numeric\n",
    "for col in (\"Population_2021\",\"Total_households\",\"Median_income_2020\"):\n",
    "    if col in inter.columns:\n",
    "        inter[col] = pd.to_numeric(inter[col], errors=\"coerce\")\n",
    "\n",
    "# Weighted aggregation per branch/time band\n",
    "def _agg(df):\n",
    "    w = df[\"w\"]\n",
    "    out = {}\n",
    "    if \"Population_2021\" in df:\n",
    "        out[\"Population_2021\"] = (df[\"Population_2021\"] * w).sum()\n",
    "    if \"Total_households\" in df:\n",
    "        out[\"Total_households\"] = (df[\"Total_households\"] * w).sum()\n",
    "    if \"Median_income_2020\" in df:\n",
    "        # area-weighted mean (proxy). If you want HH-weighted, use Total_households * w instead of w.\n",
    "        out[\"Median_income_2020_wavg\"] = (df[\"Median_income_2020\"] * w).sum() / (w.sum() or 1)\n",
    "    out[\"DAs_covered\"] = df[\"DAUID\"].nunique()\n",
    "    out[\"Area_m2\"] = df[\"part_area_m2\"].sum()\n",
    "    return pd.Series(out)\n",
    "\n",
    "agg = (inter.groupby([\"FacilityID\",\"ToBreak\"], as_index=False)\n",
    "             .apply(_agg)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# Nice ordering of bands (if ToBreak is numeric-like)\n",
    "try:\n",
    "    agg[\"ToBreak\"] = agg[\"ToBreak\"].astype(float).astype(int)\n",
    "    agg = agg.sort_values([\"FacilityID\",\"ToBreak\"])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Save table\n",
    "agg.to_csv(OUT_TABLE, index=False)\n",
    "print(\"Saved table:\", OUT_TABLE)\n",
    "\n",
    "# (Optional) save a geo layer of intersected pieces for QA maps\n",
    "inter.to_file(OUT_GEO, driver=\"GeoJSON\")\n",
    "inter.to_file(OUT_SHP, driver=\"ESRI Shapefile\")\n",
    "print(\"✅ Saved GeoJSON and SHP in data/outputs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter.to_file(\"data/outputs/trade_area_demographics.shp\", driver=\"ESRI Shapefile\")\n",
    "print(\"✅ Saved GeoJSON and SHP in data/outputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b89268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FacilityID  ToBreak  Population_2021  Total_households  \\\n",
      "0           1        5     49366.651118      25589.675273   \n",
      "1           1       10    101681.061862      43135.901684   \n",
      "2           1       15    216451.162989      98861.121962   \n",
      "3           2        5     48781.379375      17364.216567   \n",
      "4           2       10    261300.419289      91768.718319   \n",
      "\n",
      "   Median_income_2020_wavg  DAs_covered       Area_m2  \n",
      "0            136414.097184         74.0  4.981015e+06  \n",
      "1            169014.367547        218.0  2.018371e+07  \n",
      "2            129920.023271        438.0  4.827144e+07  \n",
      "3             87636.386778         96.0  1.254643e+07  \n",
      "4             90529.539601        503.0  7.169699e+07  \n",
      "         Population_2021  Total_households       Area_m2\n",
      "ToBreak                                                 \n",
      "5           4.611406e+05      1.913374e+05  1.318974e+08\n",
      "10          1.776814e+06      6.696874e+05  7.250504e+08\n",
      "15          2.804371e+06      1.050634e+06  1.835346e+09\n"
     ]
    }
   ],
   "source": [
    "print(agg.head())\n",
    "print(agg.groupby(\"ToBreak\")[[\"Population_2021\",\"Total_households\",\"Area_m2\"]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038b2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a114771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths (adjust to your folders)\n",
    "DEMAND = \"data/processed/Demand_Centers.shp\"         # output from Mean Center (1 point per cluster)\n",
    "BRANCH  = \"data/branches/branches.shp\"               # your branch points\n",
    "DEMOCSV = \"data/outputs/trade_area_demographics.csv\" # optional (for attractiveness from 5-min band)\n",
    "\n",
    "dc = gpd.read_file(DEMAND)\n",
    "br = gpd.read_file(BRANCH)\n",
    "dc = dc.rename(columns={\"SUM_Popula\":\"pop_w\"})  # ensure population weight column name\n",
    "if \"pop_w\" not in dc.columns:\n",
    "    raise ValueError(\"Demand centers must include SUM_Population_2021 (renamed to pop_w).\")\n",
    "\n",
    "# Keep only needed cols\n",
    "dc = dc[[\"CLUSTER_ID\",\"pop_w\",\"geometry\"]].copy()\n",
    "if \"BranchID\" in br.columns: \n",
    "    br[\"FacilityID\"] = br.index.astype(str)\n",
    "elif \"BranchID\" not in br.columns:\n",
    "    br = br.rename(columns={\"FacilityID\":\"BranchID\"})\n",
    "\n",
    "br[\"StoreAttr\"] = (\n",
    "    br[\"StoreAttr\"]\n",
    "    .astype(str)            # ensure string\n",
    "    .str.replace(\",\", \"\", regex=False)  # remove commas\n",
    "    .astype(float)          # convert to float (or int if safe)\n",
    ")\n",
    "br[\"StoreAttr\"] = pd.to_numeric(br[\"StoreAttr\"], errors=\"raise\")\n",
    "br = br[[\"BranchID\",\"geometry\", \"StoreAttr\"]].copy()\n",
    "\n",
    "# Ensure both layers are in WGS84 for haversine\n",
    "if dc.crs is None or dc.crs.to_epsg() != 4326: dc = dc.to_crs(4326)\n",
    "if br.crs is None or br.crs.to_epsg() != 4326: br = br.to_crs(4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b385dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BranchID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>StoreAttr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-79.3936 43.7128)</td>\n",
       "      <td>239199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-79.2331 43.7813)</td>\n",
       "      <td>279304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-79.5452 43.6382)</td>\n",
       "      <td>197907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-79.6441 43.589)</td>\n",
       "      <td>200416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POINT (-79.7632 43.7315)</td>\n",
       "      <td>223465.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BranchID                  geometry  StoreAttr\n",
       "0         1  POINT (-79.3936 43.7128)   239199.0\n",
       "1         2  POINT (-79.2331 43.7813)   279304.0\n",
       "2         3  POINT (-79.5452 43.6382)   197907.0\n",
       "3         4   POINT (-79.6441 43.589)   200416.0\n",
       "4         5  POINT (-79.7632 43.7315)   223465.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7265206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized haversine\n",
    "def hav_km(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0088\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2*R*np.arcsin(np.sqrt(a))\n",
    "\n",
    "dc_coords = np.vstack([dc.geometry.y.values, dc.geometry.x.values]).T  # lat, lon\n",
    "br_coords = np.vstack([br.geometry.y.values, br.geometry.x.values]).T\n",
    "\n",
    "# pairwise distances: (n_demand x n_branches)\n",
    "dist_mat = np.empty((dc_coords.shape[0], br_coords.shape[0]), dtype=\"float64\")\n",
    "for j, (lat2, lon2) in enumerate(br_coords):\n",
    "    dist_mat[:, j] = hav_km(dc_coords[:,0], dc_coords[:,1], lat2, lon2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298d3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "beta = 1.8  # distance decay\n",
    "\n",
    "A = br[\"StoreAttr\"].values.reshape(1, -1)          # (1 x nb)\n",
    "D = np.clip(dist_mat, 0.1, None)                    # avoid divide by zero (0.1 km minimum)\n",
    "\n",
    "W = A / (D ** beta)                                 # (nd x nb)\n",
    "den = W.sum(axis=1, keepdims=True)                  # sum over branches per demand\n",
    "P = W / np.where(den==0, 1, den)                    # probabilities P_ij\n",
    "\n",
    "# Expected customers from each demand center to each branch\n",
    "pop_w = dc[\"pop_w\"].values.reshape(-1, 1)           # (nd x 1)\n",
    "E = P * pop_w                                       # expected_cust_ij\n",
    "\n",
    "# Long table for export\n",
    "ij = np.transpose(np.nonzero(np.ones_like(P, dtype=bool)))  # all pairs\n",
    "out = pd.DataFrame({\n",
    "    \"OriginID\": dc[\"CLUSTER_ID\"].values[ij[:,0]],\n",
    "    \"BranchID\": br[\"BranchID\"].values[ij[:,1]],\n",
    "    \"prob\": P[ij[:,0], ij[:,1]],\n",
    "    \"expected_cust\": E[ij[:,0], ij[:,1]],\n",
    "    \"distance_km\": D[ij[:,0], ij[:,1]],\n",
    "    \"StoreAttr\": br[\"StoreAttr\"].values[ij[:,1]]\n",
    "})\n",
    "\n",
    "# Branch market share\n",
    "market = (out.groupby(\"BranchID\", as_index=False)\n",
    "             .agg(expected_cust=(\"expected_cust\",\"sum\")))\n",
    "market[\"market_share_%\"] = 100 * market[\"expected_cust\"] / market[\"expected_cust\"].sum()\n",
    "\n",
    "# Dominant branch per demand center (for mapping)\n",
    "max_idx = np.argmax(P, axis=1)\n",
    "dc_dom = dc[[\"CLUSTER_ID\",\"geometry\"]].copy()\n",
    "dc_dom[\"DomBranch\"] = br[\"BranchID\"].values[max_idx]\n",
    "dc_dom[\"DomProb\"]   = P[np.arange(P.shape[0]), max_idx]\n",
    "dc_dom[\"PopWeighted\"] = pop_w.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412e31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/outputs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out.to_csv(\"data/outputs/huff_od_probabilities.csv\", index=False)\n",
    "market.to_csv(\"data/outputs/huff_market_share.csv\", index=False)\n",
    "dc_dom.to_file(\"data/outputs/huff_demand_dominant.geojson\", driver=\"GeoJSON\")  # quick map QA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb8c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = dc_dom.copy()\n",
    "gdf[\"lat\"] = gdf.geometry.y\n",
    "gdf[\"lon\"] = gdf.geometry.x\n",
    "gdf.drop(columns=\"geometry\").to_csv(\"data/outputs/huff_demand_dominant.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6fff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopanda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
